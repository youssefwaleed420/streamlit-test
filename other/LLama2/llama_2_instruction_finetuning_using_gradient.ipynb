{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youssefwaleed420/streamlit-test/blob/main/Question%20Answer%20Models/LLama2/llama_2_instruction_finetuning_using_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIl0T94ewteO",
        "outputId": "c611cae9-03bc-4942-97a7-b10102ca1b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.2.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.3/166.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0.0,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from gradientai) (1.10.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, gradientai\n",
            "Successfully installed aenum-3.1.15 gradientai-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = \"1xFpB1xiq612F7qOOa8zHIpSaIVK7U9O\"\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = \"0f99a5d5-209f-43de-b5e4-dd07456cf183_workspace\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPPGo7rZx6lZ",
        "outputId": "00bf5966-03aa-45bf-96b6-009e05d807d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "def main():\n",
        "  with Gradient() as gradient:\n",
        "      base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "      new_model_adapter = base_model.create_model_adapter(\n",
        "          name=\"test model 3\"\n",
        "      )\n",
        "      print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "      sample_query = \"### Instruction: Who is Matthew Berman? \\n\\n### Response:\"\n",
        "      print(f\"Asking: {sample_query}\")\n",
        "\n",
        "      # before fine-tuning\n",
        "      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "      print(f\"Generated (before fine-tune): {completion}\")\n",
        "\n",
        "      samples = [\n",
        "        { \"inputs\": \"### Instruction: Who is Matthew Berman? \\n\\n### Response: Matthew Berman is a popular video creator who talks about AI\" },\n",
        "        { \"inputs\": \"### Instruction: Who is the person named Matthew Berman ? \\n\\n### Response: Matthew Berman is a YouTuber who talks about AI\" },\n",
        "        { \"inputs\": \"### Instruction: Can you tell me about Matthew Berman? \\n\\n### Response: Matthew Berman is a popular creator who specializes in AI content\" },\n",
        "      ]\n",
        "\n",
        "      # this is where fine-tuning happens\n",
        "      # num_epochs is the number of times you fine-tune the model\n",
        "      # more epochs tends to get better results, but you also run the risk of \"overfitting\"\n",
        "      # play around with this number to find what works best for you\n",
        "      num_epochs = 3\n",
        "      count = 0\n",
        "      while count < num_epochs:\n",
        "          print(f\"Fine-tuning the model, iteration {count + 1}\")\n",
        "          new_model_adapter.fine_tune(samples=samples)\n",
        "          count = count + 1\n",
        "\n",
        "      # after fine-tuning\n",
        "      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "      print(f\"Generated (after fine-tune): {completion}\")\n",
        "\n",
        "      new_model_adapter.delete()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl475npAx9X4",
        "outputId": "aa110a98-fc94-47e3-c194-c5ce76119367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 1ab853c2-b374-4ae7-b42d-2bbc82b41b83_model_adapter\n",
            "Asking: ### Instruction: Who is Matthew Berman? \n",
            "\n",
            "### Response:\n",
            "Generated (before fine-tune): Matthew Berman is a writer and producer, known for his work on the television series \"The Comeback\" and \"Curb Your Enthusiasm\".\n",
            "Fine-tuning the model, iteration 1\n",
            "Fine-tuning the model, iteration 2\n",
            "Fine-tuning the model, iteration 3\n",
            "Generated (after fine-tune): Matthew Berman is a popular creator who talks about AI and its impact on society.\n"
          ]
        }
      ]
    }
  ]
}